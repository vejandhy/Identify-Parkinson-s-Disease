{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# A brief description about Parkinson\u2019s disease\n\nParkinson\u2019s disease is a type of disorder of the central nervous system that effects movement and inducing tremors and stiffness. It has 5 stages to it and affects more than 1 million individuals every year in India. This is chronic and has no cure yet. It is a neuro-degenerative disorder affecting dopamine-producing neurons in the brain."}, {"metadata": {}, "cell_type": "markdown", "source": "# Reason behind using XGBoost algorithm?\n\nXGBoost is a new Machine Learning algorithm designed with speed and performance. XGBoost stands for eXtreme Gradient Boosting and is based on decision trees. In this project, we will import the XGBClassifier from the XGBoost library. This is an implementation of the scikit-learn API for XGBoost classification.\n\n## Objective\n\nTo build a model accurately by detecting the presence of Parkinson\u2019s disease in an individual.\n\n## Summarization of the Project\n\nIn this project, we will use python libraries such as pandas, numpy, xgboost, scikit-learn and build a model using XGB-Classifier. We will first load the data, get the features & labels, then scale the features and labels followed by building an XGBClassifier. Finally we will calculate the accuracy of the model.\n\n### Dataset for ML Project\n\nWe'll use UCI ML Parkinson's dataset that has 24 columns and 195 rows (recods)."}, {"metadata": {}, "cell_type": "code", "source": "pip install numpy pandas sklearn xgboost", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: numpy in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.20.3)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.3.4)\nRequirement already satisfied: sklearn in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (0.0.post1)\nRequirement already satisfied: xgboost in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.5.2)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas) (2021.3)\nRequirement already satisfied: scipy in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from xgboost) (1.7.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nNote: you may need to restart the kernel to use updated packages.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Prerequisites\n## Install the below libraries with PIP command, if not done already;\n\n### Import necessary python libraries;\n\nimport numpy as np\nimport pandas as pd\nimport os, sys\nfrom sklearn.preprocessing import MinMaxScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# @hidden_cell\n\n\n# This connection object is used to access your data and contains your credentials or project token.\n# You might want to remove those credentials before you share your notebook.\n\n\nimport types\nimport pandas as pd\nimport ibm_boto3\nfrom botocore.client import Config\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\n\nparkinson_raw_data_DataCatalog_client = ibm_boto3.client(\n    service_name='s3',\n    ibm_api_key_id='t0KWR7UL3KHsbne82tV0D78dE6Sl_1bCRtot5OQomA4r',\n    ibm_service_instance_id='crn:v1:bluemix:public:cloud-object-storage:global:a/1b2b5c94e0474dd8a23f976cedd9f9ef:787f4e57-72e8-49f0-b22b-e687fa22da71::',\n    ibm_auth_endpoint='https://iam.cloud.ibm.com/identity/token',\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.us-south.cloud-object-storage.appdomain.cloud'\n)\n\n# Your data file is loaded into a botocore.response.StreamingBody object.\n# Refer to the documentation of ibm_boto3 and pandas for other possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nraw_data_1 = parkinson_raw_data_DataCatalog_client.get_object(Bucket='parkinsonrawdata-datacatalog-trlocmasjcomv3hcmwmgr', Key='data_asset/parkinsons_MBU4ANWQs946q5X9keBzj.data')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(raw_data_1, \"__iter__\"): raw_data_1.__iter__ = types.MethodType( __iter__, raw_data_1 ) \n", "execution_count": 56, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "credentials_local = {\n    'IAM_SERVICE_ID': 'crn:v1:bluemix:public:cloud-object-storage:global:a/1b2b5c94e0474dd8a23f976cedd9f9ef:787f4e57-72e8-49f0-b22b-e687fa22da71::',\n    'IBM_API_KEY_ID': 't0KWR7UL3KHsbne82tV0D78dE6Sl_1bCRtot5OQomA4r',\n    'ENDPOINT': 'https://s3.us-south.cloud-object-storage.appdomain.cloud',\n    'IBM_AUTH_ENDPOINT': 'https://iam.cloud.ibm.com/identity/token',\n    'BUCKET': 'parkinsonrawdata-datacatalog-trlocmasjcomv3hcmwmgr'\n}\nclient_cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials_local['IBM_API_KEY_ID'],\n    ibm_auth_endpoint=credentials_local['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials_local['ENDPOINT'])", "execution_count": 62, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "body = client_cos.get_object(Bucket=credentials_local['parkinson-raw-data'], Key=\"parkinsons.data\")['Body'].read()\ndf = pd.read_csv(BytesIO(body))", "execution_count": 65, "outputs": [{"output_type": "error", "ename": "KeyError", "evalue": "'parkinson-raw-data'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_164/606411374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_cos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials_local\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parkinson-raw-data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"parkinsons.data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mKeyError\u001b[0m: 'parkinson-raw-data'"]}]}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='c5X6bp8xmJiVqN3CciJHx8kcUPSoz7NJ8AKhaRhb1mBM',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'identifyparkinson39sdisease-donotdelete-pr-pf7fxmtfebi3c0'\nobject_key = 'parkinsons.csv'\n\nbody = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()\n", "execution_count": 66, "outputs": [{"output_type": "execute_result", "execution_count": 66, "data": {"text/plain": "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n\n   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n\n   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n\n    spread2        D2       PPE  \n0  0.266482  2.301442  0.284654  \n1  0.335590  2.486855  0.368674  \n2  0.311173  2.342259  0.332634  \n3  0.334147  2.405554  0.368975  \n4  0.234513  2.332180  0.410335  \n\n[5 rows x 24 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>MDVP:Fo(Hz)</th>\n      <th>MDVP:Fhi(Hz)</th>\n      <th>MDVP:Flo(Hz)</th>\n      <th>MDVP:Jitter(%)</th>\n      <th>MDVP:Jitter(Abs)</th>\n      <th>MDVP:RAP</th>\n      <th>MDVP:PPQ</th>\n      <th>Jitter:DDP</th>\n      <th>MDVP:Shimmer</th>\n      <th>...</th>\n      <th>Shimmer:DDA</th>\n      <th>NHR</th>\n      <th>HNR</th>\n      <th>status</th>\n      <th>RPDE</th>\n      <th>DFA</th>\n      <th>spread1</th>\n      <th>spread2</th>\n      <th>D2</th>\n      <th>PPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>phon_R01_S01_1</td>\n      <td>119.992</td>\n      <td>157.302</td>\n      <td>74.997</td>\n      <td>0.00784</td>\n      <td>0.00007</td>\n      <td>0.00370</td>\n      <td>0.00554</td>\n      <td>0.01109</td>\n      <td>0.04374</td>\n      <td>...</td>\n      <td>0.06545</td>\n      <td>0.02211</td>\n      <td>21.033</td>\n      <td>1</td>\n      <td>0.414783</td>\n      <td>0.815285</td>\n      <td>-4.813031</td>\n      <td>0.266482</td>\n      <td>2.301442</td>\n      <td>0.284654</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>phon_R01_S01_2</td>\n      <td>122.400</td>\n      <td>148.650</td>\n      <td>113.819</td>\n      <td>0.00968</td>\n      <td>0.00008</td>\n      <td>0.00465</td>\n      <td>0.00696</td>\n      <td>0.01394</td>\n      <td>0.06134</td>\n      <td>...</td>\n      <td>0.09403</td>\n      <td>0.01929</td>\n      <td>19.085</td>\n      <td>1</td>\n      <td>0.458359</td>\n      <td>0.819521</td>\n      <td>-4.075192</td>\n      <td>0.335590</td>\n      <td>2.486855</td>\n      <td>0.368674</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>phon_R01_S01_3</td>\n      <td>116.682</td>\n      <td>131.111</td>\n      <td>111.555</td>\n      <td>0.01050</td>\n      <td>0.00009</td>\n      <td>0.00544</td>\n      <td>0.00781</td>\n      <td>0.01633</td>\n      <td>0.05233</td>\n      <td>...</td>\n      <td>0.08270</td>\n      <td>0.01309</td>\n      <td>20.651</td>\n      <td>1</td>\n      <td>0.429895</td>\n      <td>0.825288</td>\n      <td>-4.443179</td>\n      <td>0.311173</td>\n      <td>2.342259</td>\n      <td>0.332634</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>phon_R01_S01_4</td>\n      <td>116.676</td>\n      <td>137.871</td>\n      <td>111.366</td>\n      <td>0.00997</td>\n      <td>0.00009</td>\n      <td>0.00502</td>\n      <td>0.00698</td>\n      <td>0.01505</td>\n      <td>0.05492</td>\n      <td>...</td>\n      <td>0.08771</td>\n      <td>0.01353</td>\n      <td>20.644</td>\n      <td>1</td>\n      <td>0.434969</td>\n      <td>0.819235</td>\n      <td>-4.117501</td>\n      <td>0.334147</td>\n      <td>2.405554</td>\n      <td>0.368975</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>phon_R01_S01_5</td>\n      <td>116.014</td>\n      <td>141.781</td>\n      <td>110.655</td>\n      <td>0.01284</td>\n      <td>0.00011</td>\n      <td>0.00655</td>\n      <td>0.00908</td>\n      <td>0.01966</td>\n      <td>0.06425</td>\n      <td>...</td>\n      <td>0.10470</td>\n      <td>0.01767</td>\n      <td>19.649</td>\n      <td>1</td>\n      <td>0.417356</td>\n      <td>0.823484</td>\n      <td>-3.747787</td>\n      <td>0.234513</td>\n      <td>2.332180</td>\n      <td>0.410335</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 24 columns</p>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Get the features and labels from the DataFrame (dataset). \n## The features are all the columns except \u2018status\u2019, and the labels are those in the \u2018status\u2019 column.\n\nfeatures=df_data_1.loc[:,df_data_1.columns!='status'].values[:,1:]\nlabels=df_data_1.loc[:,'status'].values", "execution_count": 67, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# The \u2018status\u2019 column has values 0 and 1 as labels; \n## let\u2019s get the counts of these labels for both- 0 and 1\n\nprint(labels[labels==1].shape[0], labels[labels==0].shape[0])", "execution_count": 68, "outputs": [{"output_type": "stream", "text": "147 48\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# We have 147 ones and 48 zeros in the status column in our dataset.", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Initialize a MinMaxScaler and scale the features between -1 and 1 to normalize them.\n## The MinMaxScaler transforms features by scaling them to a given range. \n### The fit_transform() method fits to the data and then transforms it. We don\u2019t need to scale the labels.\n\nscaler=MinMaxScaler((-1,1))\nx=scaler.fit_transform(features)\ny=labels", "execution_count": 69, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Now, split the dataset into training and testing sets keeping 20% of the data for testing.\n\nx_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.2, random_state=7)", "execution_count": 70, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Initialize an XGBClassifier and train the model.\n## This classifies using eXtreme Gradient Boosting- using gradient boosting algorithms for modern data science problems. \n### It falls under the category of Ensemble Learning in ML, where we train and predict using many models to produce one superior output.\n\nmodel=XGBClassifier()\nmodel.fit(x_train,y_train)", "execution_count": 74, "outputs": [{"output_type": "stream", "text": "[15:42:47] WARNING: /opt/conda/conda-bld/xgboost-ext_1658814095305/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 74, "data": {"text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n              gamma=0, gpu_id=-1, importance_type=None,\n              interaction_constraints='', learning_rate=0.300000012,\n              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n              monotone_constraints='()', n_estimators=100, n_jobs=56,\n              num_parallel_tree=1, predictor='auto', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Find the Accuracy of the model\n## Finally, generate y_pred (predicted values for x_test) and calculate the accuracy for the model. Print it out.\n\ny_pred=model.predict(x_test)\nprint(accuracy_score(y_test, y_pred)*100)", "execution_count": 75, "outputs": [{"output_type": "stream", "text": "94.87179487179486\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Conclusion\n\n### In this Python machine learning project, we learned to detect the presence of Parkinson\u2019s Disease in individuals using various factors. We used an XGBClassifier for this and made use of the sklearn library to prepare the dataset. This gives us an accuracy of 94.87%, which is great considering the number of lines of code in this python project."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}